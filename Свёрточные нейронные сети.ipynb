{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6788b517-c650-489d-a9e0-db6c4781c49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "np.random.seed(17)\n",
    "tf.random.set_seed(17)\n",
    "random.seed(17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "281b34ba-55bb-4f23-941d-86fb035becb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = tf.keras.applications.DenseNet201()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1bf29de9-4a39-4b52-9401-8e1f3fefde2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pillow in /opt/anaconda3/lib/python3.12/site-packages (10.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e07f2f7a-95b4-4602-8783-30b9878104cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cat_img = tf.keras.preprocessing.image.load_img('cat.jpg', target_size=(224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "642ec665-e325-4e26-a69c-3da458e8d085",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d84ed626-76e4-4ee6-a4fc-a44e43c0b8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# далее необходимо представить картинку в виде массива\n",
    "\n",
    "cat_img_array = image.img_to_array(cat_img)\n",
    "cat_img_array = np.expand_dims(cat_img_array, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2d169da-2d5f-4f35-aae9-0dfaad6fe6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем предобученную модель DenseNet201\n",
    "model = tf.keras.applications.DenseNet201(weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a2d04e3-4c0d-49a7-91c9-e14f083349e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Предобрабатываем изображение\n",
    "processed_img = tf.keras.applications.densenet.preprocess_input(cat_img_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3d8144d-6ca6-4a2b-817b-d28795dbbd0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(processed_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11dfb0d6-9576-4fed-95be-c85a8c3e7496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Декодируем предсказания\n",
    "decoded_pred = tf.keras.applications.densenet.decode_predictions(pred, top=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3a3ff65-2b87-4515-bdb0-28bf6d0ffe5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('n02124075', 'Egyptian_cat', 0.16333994)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca19d4ed-808d-4a61-8b06-2a25cd22d1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Замораживаем все слои\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f05acf22-aa1e-4069-9bde-efe1a44611a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Размораживаем последние 10 слоев\n",
    "for layer in model.layers[-10:]:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "39e10d66-6b2d-4163-b302-70f5d88e1535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# заменим активацию на последнем слое\n",
    "\n",
    "model.layers[-1].activation = tf.keras.activations.relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "13b4c95e-eef5-4f59-b55d-3b08076a50e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем новую модель для бинарной классификации\n",
    "model_cats = tf.keras.models.Sequential([\n",
    "   model,\n",
    "   tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "815a88ca-a8ba-4366-82be-13e2c4ed566c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# скомпилируем получившуюся модель, добавив необходимые метрики\n",
    "\n",
    "accuracy = tf.keras.metrics.binary_accuracy\n",
    "precision = tf.keras.metrics.Precision()\n",
    "recall = tf.keras.metrics.Recall()\n",
    "\n",
    "# как и в прошлый раз, F1 напишем сами\n",
    "def f1_metrics(y_true, y_pred):\n",
    "    prec = precision(y_true, y_pred)\n",
    "    rec = recall(y_true, y_pred)\n",
    "    return 2 * ((prec * rec) / (prec + rec + 1e-7))\n",
    "    \n",
    "model_cats.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.00001),\n",
    "                   loss=tf.keras.losses.binary_crossentropy,\n",
    "                   metrics=[accuracy, precision, recall, f1_metrics])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "58def40e-9b3f-41e6-948b-0569efa93a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество тренируемых параметров: 2204625\n"
     ]
    }
   ],
   "source": [
    "trainable_params = np.sum([tf.keras.backend.count_params(w) for w in model_cats.trainable_weights])\n",
    "print(f\"Количество тренируемых параметров: {trainable_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7dd9d867-b266-44b0-b759-db58b4fd526e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция предподготовки картинки для модели\n",
    "\n",
    "def preprocess_image(file):\n",
    "    img = tf.keras.preprocessing.image.load_img(file, target_size=(224, 224))  # загружаем в нужном разрешении\n",
    "    img = tf.keras.preprocessing.image.img_to_array(img)  # конвертируем в массив\n",
    "    img = tf.keras.applications.densenet.preprocess_input(img)  # препроцессинг для resnet\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ddbcaab3-e0c0-48e8-82a0-16180dc20feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5ae8ba4f-ba1e-41e6-b175-a5411a751133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# добавляем пары (картинка, 1) для картинок с котами\n",
    "cats = [(preprocess_image('pics/cats/'+file), 1) for file in os.listdir('pics/cats')]\n",
    "\n",
    "# и пары (картинка, 0) для картинок без котов\n",
    "nocats = [(preprocess_image('pics/nocats/'+file), 0) for file in os.listdir('pics/nocats')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9525c8f8-61a4-4977-941e-5593c96b9c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# сливаем оба списка вместе\n",
    "\n",
    "all_pics = cats + nocats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8dd82464-8371-400d-bbe6-d1407adab6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# и перемешиваем данные\n",
    "\n",
    "random.shuffle(all_pics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c7b951b0-f753-4b7e-8fc8-aded2c3a13a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# в x отправляем картинки, а в y - прикреплённые к ним лейблы\n",
    "\n",
    "x = np.array([a[0] for a in all_pics])\n",
    "y = np.array([a[1] for a in all_pics])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e4dda7e3-fcff-4d5b-aa0b-cbf59c5b7e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# делим данные на трейн, валидацию и тест традиционным образом\n",
    "\n",
    "def train_val_test_split(x, val_frac=0.15, test_frac=0.15):\n",
    "    x_train = x[:round((1 - val_frac - test_frac) * len(x))]\n",
    "    x_val = x[round((1 - val_frac - test_frac) * len(x)):round((1 - test_frac) * len(x))]\n",
    "    x_test = x[round((1 - test_frac) * len(x)):]\n",
    "    return x_train, x_val, x_test\n",
    "\n",
    "\n",
    "x_train, x_val, x_test = train_val_test_split(x)\n",
    "y_train, y_val, y_test = train_val_test_split(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9593a57a-a844-4b54-87ec-be2b3e7b1660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# настроек у этого класса куда больше, но для примера возьмём только самые основные \n",
    "\n",
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "db82c2f8-11b0-4f87-b455-24ec9da5707a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# будем отслеживать обучение в Tensorboard\n",
    "\n",
    "tb_callback = tf.keras.callbacks.TensorBoard(log_dir='logs/tl_densenet_cats', histogram_freq=1)\n",
    "\n",
    "# и уменьшать lr на плато\n",
    "\n",
    "annealing = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533ce96c-03ff-4f65-858b-2ca8f9fff566",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e1fbee7e-001b-4fc1-9719-94db5de630a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 997ms/step - binary_accuracy: 0.4393 - f1_metrics: 0.3740 - loss: 1.0719 - precision_1: 0.3315 - recall_1: 0.5315 - val_binary_accuracy: 0.4706 - val_f1_metrics: 0.3602 - val_loss: 0.9026 - val_precision_1: 0.3226 - val_recall_1: 0.4000 - learning_rate: 1.0000e-05\n",
      "Epoch 2/50\n",
      "\u001b[1m 1/20\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 598ms/step - binary_accuracy: 0.4375 - f1_metrics: 0.4706 - loss: 0.8668 - precision_1: 0.5000 - recall_1: 0.4444"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/trainers/epoch_iterator.py:116: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 291ms/step - binary_accuracy: 0.4375 - f1_metrics: 0.4706 - loss: 0.8668 - precision_1: 0.5000 - recall_1: 0.4444 - val_binary_accuracy: 0.4706 - val_f1_metrics: 0.3602 - val_loss: 0.8928 - val_precision_1: 0.3226 - val_recall_1: 0.4000 - learning_rate: 1.0000e-05\n",
      "Epoch 3/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 862ms/step - binary_accuracy: 0.5180 - f1_metrics: 0.3997 - loss: 0.8581 - precision_1: 0.3798 - recall_1: 0.4224 - val_binary_accuracy: 0.5294 - val_f1_metrics: 0.3921 - val_loss: 0.7453 - val_precision_1: 0.3704 - val_recall_1: 0.4000 - learning_rate: 1.0000e-05\n",
      "Epoch 4/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 292ms/step - binary_accuracy: 0.5000 - f1_metrics: 0.0000e+00 - loss: 0.9901 - precision_1: 0.0000e+00 - recall_1: 0.0000e+00 - val_binary_accuracy: 0.5294 - val_f1_metrics: 0.3921 - val_loss: 0.7398 - val_precision_1: 0.3704 - val_recall_1: 0.4000 - learning_rate: 1.0000e-05\n",
      "Epoch 5/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 896ms/step - binary_accuracy: 0.5906 - f1_metrics: 0.4206 - loss: 0.7703 - precision_1: 0.4522 - recall_1: 0.4333 - val_binary_accuracy: 0.6324 - val_f1_metrics: 0.5581 - val_loss: 0.6343 - val_precision_1: 0.5000 - val_recall_1: 0.5600 - learning_rate: 1.0000e-05\n",
      "Epoch 6/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 292ms/step - binary_accuracy: 1.0000 - f1_metrics: 0.0000e+00 - loss: 0.2693 - precision_1: 0.0000e+00 - recall_1: 0.0000e+00 - val_binary_accuracy: 0.6324 - val_f1_metrics: 0.5581 - val_loss: 0.6289 - val_precision_1: 0.5000 - val_recall_1: 0.5600 - learning_rate: 1.0000e-05\n",
      "Epoch 7/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 880ms/step - binary_accuracy: 0.6525 - f1_metrics: 0.5200 - loss: 0.6786 - precision_1: 0.5269 - recall_1: 0.4414 - val_binary_accuracy: 0.6765 - val_f1_metrics: 0.5884 - val_loss: 0.5497 - val_precision_1: 0.5600 - val_recall_1: 0.5600 - learning_rate: 1.0000e-05\n",
      "Epoch 8/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 296ms/step - binary_accuracy: 0.6250 - f1_metrics: 0.6250 - loss: 0.6802 - precision_1: 0.7143 - recall_1: 0.5556 - val_binary_accuracy: 0.6765 - val_f1_metrics: 0.5884 - val_loss: 0.5462 - val_precision_1: 0.5600 - val_recall_1: 0.5600 - learning_rate: 1.0000e-05\n",
      "Epoch 9/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 912ms/step - binary_accuracy: 0.6754 - f1_metrics: 0.5494 - loss: 0.6145 - precision_1: 0.5766 - recall_1: 0.5517 - val_binary_accuracy: 0.7206 - val_f1_metrics: 0.6867 - val_loss: 0.4972 - val_precision_1: 0.5938 - val_recall_1: 0.7600 - learning_rate: 1.0000e-05\n",
      "Epoch 10/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 307ms/step - binary_accuracy: 0.7500 - f1_metrics: 0.6667 - loss: 0.3399 - precision_1: 0.5000 - recall_1: 1.0000 - val_binary_accuracy: 0.7206 - val_f1_metrics: 0.6867 - val_loss: 0.4947 - val_precision_1: 0.5938 - val_recall_1: 0.7600 - learning_rate: 1.0000e-05\n",
      "Epoch 11/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 889ms/step - binary_accuracy: 0.7508 - f1_metrics: 0.6401 - loss: 0.5149 - precision_1: 0.6786 - recall_1: 0.6552 - val_binary_accuracy: 0.7794 - val_f1_metrics: 0.7377 - val_loss: 0.4425 - val_precision_1: 0.6667 - val_recall_1: 0.8000 - learning_rate: 1.0000e-05\n",
      "Epoch 12/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 302ms/step - binary_accuracy: 0.8125 - f1_metrics: 0.6667 - loss: 0.5806 - precision_1: 0.6000 - recall_1: 0.7500 - val_binary_accuracy: 0.7794 - val_f1_metrics: 0.7377 - val_loss: 0.4400 - val_precision_1: 0.6667 - val_recall_1: 0.8000 - learning_rate: 1.0000e-05\n",
      "Epoch 13/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 929ms/step - binary_accuracy: 0.7803 - f1_metrics: 0.6237 - loss: 0.4717 - precision_1: 0.7333 - recall_1: 0.6638 - val_binary_accuracy: 0.8529 - val_f1_metrics: 0.8487 - val_loss: 0.4028 - val_precision_1: 0.7273 - val_recall_1: 0.9600 - learning_rate: 1.0000e-05\n",
      "Epoch 14/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 308ms/step - binary_accuracy: 0.8125 - f1_metrics: 0.5714 - loss: 0.5009 - precision_1: 0.6667 - recall_1: 0.5000 - val_binary_accuracy: 0.8529 - val_f1_metrics: 0.8487 - val_loss: 0.4023 - val_precision_1: 0.7273 - val_recall_1: 0.9600 - learning_rate: 1.0000e-05\n",
      "Epoch 15/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 919ms/step - binary_accuracy: 0.8219 - f1_metrics: 0.7678 - loss: 0.4443 - precision_1: 0.7739 - recall_1: 0.7417 - val_binary_accuracy: 0.8529 - val_f1_metrics: 0.8487 - val_loss: 0.3711 - val_precision_1: 0.7273 - val_recall_1: 0.9600 - learning_rate: 1.0000e-05\n",
      "Epoch 16/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 292ms/step - binary_accuracy: 1.0000 - f1_metrics: 0.0000e+00 - loss: 0.3144 - precision_1: 0.0000e+00 - recall_1: 0.0000e+00 - val_binary_accuracy: 0.8529 - val_f1_metrics: 0.8487 - val_loss: 0.3701 - val_precision_1: 0.7273 - val_recall_1: 0.9600 - learning_rate: 1.0000e-05\n",
      "Epoch 17/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 882ms/step - binary_accuracy: 0.8361 - f1_metrics: 0.7633 - loss: 0.4005 - precision_1: 0.8056 - recall_1: 0.7500 - val_binary_accuracy: 0.8676 - val_f1_metrics: 0.8689 - val_loss: 0.3454 - val_precision_1: 0.7500 - val_recall_1: 0.9600 - learning_rate: 1.0000e-05\n",
      "Epoch 18/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 297ms/step - binary_accuracy: 0.8125 - f1_metrics: 0.6667 - loss: 0.3903 - precision_1: 0.6000 - recall_1: 0.7500 - val_binary_accuracy: 0.8676 - val_f1_metrics: 0.8689 - val_loss: 0.3448 - val_precision_1: 0.7500 - val_recall_1: 0.9600 - learning_rate: 1.0000e-05\n",
      "Epoch 19/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 876ms/step - binary_accuracy: 0.8393 - f1_metrics: 0.7427 - loss: 0.3665 - precision_1: 0.7661 - recall_1: 0.8261 - val_binary_accuracy: 0.8676 - val_f1_metrics: 0.8589 - val_loss: 0.3306 - val_precision_1: 0.7500 - val_recall_1: 0.9600 - learning_rate: 1.0000e-05\n",
      "Epoch 20/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 295ms/step - binary_accuracy: 0.8125 - f1_metrics: 0.7273 - loss: 0.4523 - precision_1: 0.6667 - recall_1: 0.8000 - val_binary_accuracy: 0.8676 - val_f1_metrics: 0.8589 - val_loss: 0.3292 - val_precision_1: 0.7500 - val_recall_1: 0.9600 - learning_rate: 1.0000e-05\n",
      "Epoch 21/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 880ms/step - binary_accuracy: 0.8787 - f1_metrics: 0.8401 - loss: 0.3307 - precision_1: 0.8519 - recall_1: 0.8142 - val_binary_accuracy: 0.8971 - val_f1_metrics: 0.8846 - val_loss: 0.2933 - val_precision_1: 0.8000 - val_recall_1: 0.9600 - learning_rate: 1.0000e-05\n",
      "Epoch 22/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 302ms/step - binary_accuracy: 0.7500 - f1_metrics: 0.6667 - loss: 0.4675 - precision_1: 0.8000 - recall_1: 0.5714 - val_binary_accuracy: 0.8971 - val_f1_metrics: 0.8846 - val_loss: 0.2920 - val_precision_1: 0.8000 - val_recall_1: 0.9600 - learning_rate: 1.0000e-05\n",
      "Epoch 23/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 889ms/step - binary_accuracy: 0.8557 - f1_metrics: 0.8002 - loss: 0.3244 - precision_1: 0.8286 - recall_1: 0.7699 - val_binary_accuracy: 0.9118 - val_f1_metrics: 0.9065 - val_loss: 0.2715 - val_precision_1: 0.8276 - val_recall_1: 0.9600 - learning_rate: 1.0000e-05\n",
      "Epoch 24/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 296ms/step - binary_accuracy: 0.8750 - f1_metrics: 0.8333 - loss: 0.2199 - precision_1: 1.0000 - recall_1: 0.7143 - val_binary_accuracy: 0.9118 - val_f1_metrics: 0.9065 - val_loss: 0.2709 - val_precision_1: 0.8276 - val_recall_1: 0.9600 - learning_rate: 1.0000e-05\n",
      "Epoch 25/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 887ms/step - binary_accuracy: 0.8787 - f1_metrics: 0.8227 - loss: 0.3213 - precision_1: 0.8835 - recall_1: 0.7845 - val_binary_accuracy: 0.9118 - val_f1_metrics: 0.9065 - val_loss: 0.2583 - val_precision_1: 0.8276 - val_recall_1: 0.9600 - learning_rate: 1.0000e-05\n",
      "Epoch 26/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 301ms/step - binary_accuracy: 0.9375 - f1_metrics: 0.8571 - loss: 0.2211 - precision_1: 1.0000 - recall_1: 0.7500 - val_binary_accuracy: 0.9118 - val_f1_metrics: 0.9065 - val_loss: 0.2578 - val_precision_1: 0.8276 - val_recall_1: 0.9600 - learning_rate: 1.0000e-05\n",
      "Epoch 27/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 893ms/step - binary_accuracy: 0.8918 - f1_metrics: 0.8509 - loss: 0.2803 - precision_1: 0.8649 - recall_1: 0.8421 - val_binary_accuracy: 0.9118 - val_f1_metrics: 0.9065 - val_loss: 0.2547 - val_precision_1: 0.8276 - val_recall_1: 0.9600 - learning_rate: 1.0000e-05\n",
      "Epoch 28/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 294ms/step - binary_accuracy: 0.8750 - f1_metrics: 0.8000 - loss: 0.3213 - precision_1: 1.0000 - recall_1: 0.6667 - val_binary_accuracy: 0.9118 - val_f1_metrics: 0.9065 - val_loss: 0.2544 - val_precision_1: 0.8276 - val_recall_1: 0.9600 - learning_rate: 1.0000e-05\n",
      "Epoch 29/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 889ms/step - binary_accuracy: 0.8852 - f1_metrics: 0.8587 - loss: 0.2782 - precision_1: 0.8421 - recall_1: 0.8496 - val_binary_accuracy: 0.9118 - val_f1_metrics: 0.9065 - val_loss: 0.2406 - val_precision_1: 0.8276 - val_recall_1: 0.9600 - learning_rate: 1.0000e-05\n",
      "Epoch 30/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 298ms/step - binary_accuracy: 0.8750 - f1_metrics: 0.8571 - loss: 0.3149 - precision_1: 0.8571 - recall_1: 0.8571 - val_binary_accuracy: 0.9118 - val_f1_metrics: 0.9065 - val_loss: 0.2394 - val_precision_1: 0.8276 - val_recall_1: 0.9600 - learning_rate: 1.0000e-05\n",
      "Epoch 31/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 902ms/step - binary_accuracy: 0.9213 - f1_metrics: 0.9067 - loss: 0.2333 - precision_1: 0.9314 - recall_1: 0.8482 - val_binary_accuracy: 0.9265 - val_f1_metrics: 0.9121 - val_loss: 0.2275 - val_precision_1: 0.8571 - val_recall_1: 0.9600 - learning_rate: 1.0000e-05\n",
      "Epoch 32/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 298ms/step - binary_accuracy: 1.0000 - f1_metrics: 1.0000 - loss: 0.2331 - precision_1: 1.0000 - recall_1: 1.0000 - val_binary_accuracy: 0.9265 - val_f1_metrics: 0.9121 - val_loss: 0.2269 - val_precision_1: 0.8571 - val_recall_1: 0.9600 - learning_rate: 1.0000e-05\n",
      "Epoch 33/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 894ms/step - binary_accuracy: 0.8984 - f1_metrics: 0.8648 - loss: 0.2421 - precision_1: 0.8716 - recall_1: 0.8482 - val_binary_accuracy: 0.9265 - val_f1_metrics: 0.9121 - val_loss: 0.2251 - val_precision_1: 0.8571 - val_recall_1: 0.9600 - learning_rate: 1.0000e-05\n",
      "Epoch 34/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 300ms/step - binary_accuracy: 0.9375 - f1_metrics: 0.9333 - loss: 0.2549 - precision_1: 1.0000 - recall_1: 0.8750 - val_binary_accuracy: 0.9265 - val_f1_metrics: 0.9121 - val_loss: 0.2253 - val_precision_1: 0.8571 - val_recall_1: 0.9600 - learning_rate: 1.0000e-05\n",
      "Epoch 35/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 912ms/step - binary_accuracy: 0.9246 - f1_metrics: 0.8950 - loss: 0.2211 - precision_1: 0.9107 - recall_1: 0.8870 - val_binary_accuracy: 0.9265 - val_f1_metrics: 0.9121 - val_loss: 0.2179 - val_precision_1: 0.8571 - val_recall_1: 0.9600 - learning_rate: 1.0000e-05\n",
      "Epoch 36/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 298ms/step - binary_accuracy: 1.0000 - f1_metrics: 1.0000 - loss: 0.1999 - precision_1: 1.0000 - recall_1: 1.0000 - val_binary_accuracy: 0.9265 - val_f1_metrics: 0.9121 - val_loss: 0.2174 - val_precision_1: 0.8571 - val_recall_1: 0.9600 - learning_rate: 1.0000e-05\n",
      "Epoch 37/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 908ms/step - binary_accuracy: 0.9344 - f1_metrics: 0.8916 - loss: 0.1954 - precision_1: 0.9286 - recall_1: 0.8966 - val_binary_accuracy: 0.9265 - val_f1_metrics: 0.9121 - val_loss: 0.2089 - val_precision_1: 0.8571 - val_recall_1: 0.9600 - learning_rate: 1.0000e-05\n",
      "Epoch 38/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 316ms/step - binary_accuracy: 0.8125 - f1_metrics: 0.7273 - loss: 0.3109 - precision_1: 0.5714 - recall_1: 1.0000 - val_binary_accuracy: 0.9265 - val_f1_metrics: 0.9121 - val_loss: 0.2084 - val_precision_1: 0.8571 - val_recall_1: 0.9600 - learning_rate: 1.0000e-05\n",
      "Epoch 39/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 920ms/step - binary_accuracy: 0.9311 - f1_metrics: 0.9230 - loss: 0.2005 - precision_1: 0.9123 - recall_1: 0.9043 - val_binary_accuracy: 0.9265 - val_f1_metrics: 0.9121 - val_loss: 0.2059 - val_precision_1: 0.8571 - val_recall_1: 0.9600 - learning_rate: 1.0000e-05\n",
      "Epoch 40/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 296ms/step - binary_accuracy: 0.9375 - f1_metrics: 0.9091 - loss: 0.2759 - precision_1: 0.8333 - recall_1: 1.0000 - val_binary_accuracy: 0.9265 - val_f1_metrics: 0.9121 - val_loss: 0.2058 - val_precision_1: 0.8571 - val_recall_1: 0.9600 - learning_rate: 1.0000e-05\n",
      "Epoch 41/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 922ms/step - binary_accuracy: 0.9246 - f1_metrics: 0.8781 - loss: 0.1894 - precision_1: 0.9273 - recall_1: 0.8718 - val_binary_accuracy: 0.9265 - val_f1_metrics: 0.9121 - val_loss: 0.1976 - val_precision_1: 0.8571 - val_recall_1: 0.9600 - learning_rate: 1.0000e-05\n",
      "Epoch 42/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 303ms/step - binary_accuracy: 0.8750 - f1_metrics: 0.7500 - loss: 0.3532 - precision_1: 0.6000 - recall_1: 1.0000 - val_binary_accuracy: 0.9265 - val_f1_metrics: 0.9121 - val_loss: 0.1973 - val_precision_1: 0.8571 - val_recall_1: 0.9600 - learning_rate: 1.0000e-05\n",
      "Epoch 43/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 917ms/step - binary_accuracy: 0.9312 - f1_metrics: 0.9146 - loss: 0.1813 - precision_1: 0.9224 - recall_1: 0.8917 - val_binary_accuracy: 0.9265 - val_f1_metrics: 0.9121 - val_loss: 0.1929 - val_precision_1: 0.8571 - val_recall_1: 0.9600 - learning_rate: 1.0000e-05\n",
      "Epoch 44/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 295ms/step - binary_accuracy: 1.0000 - f1_metrics: 0.0000e+00 - loss: 0.3898 - precision_1: 0.0000e+00 - recall_1: 0.0000e+00 - val_binary_accuracy: 0.9265 - val_f1_metrics: 0.9121 - val_loss: 0.1922 - val_precision_1: 0.8571 - val_recall_1: 0.9600 - learning_rate: 1.0000e-05\n",
      "Epoch 45/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 928ms/step - binary_accuracy: 0.9443 - f1_metrics: 0.9506 - loss: 0.1855 - precision_1: 0.9444 - recall_1: 0.9027 - val_binary_accuracy: 0.9265 - val_f1_metrics: 0.9121 - val_loss: 0.1818 - val_precision_1: 0.8571 - val_recall_1: 0.9600 - learning_rate: 1.0000e-05\n",
      "Epoch 46/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 313ms/step - binary_accuracy: 0.9375 - f1_metrics: 0.9231 - loss: 0.1241 - precision_1: 1.0000 - recall_1: 0.8571 - val_binary_accuracy: 0.9265 - val_f1_metrics: 0.9121 - val_loss: 0.1817 - val_precision_1: 0.8571 - val_recall_1: 0.9600 - learning_rate: 1.0000e-05\n",
      "Epoch 47/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 905ms/step - binary_accuracy: 0.9377 - f1_metrics: 0.8896 - loss: 0.1625 - precision_1: 0.9608 - recall_1: 0.8673 - val_binary_accuracy: 0.9265 - val_f1_metrics: 0.9121 - val_loss: 0.1782 - val_precision_1: 0.8571 - val_recall_1: 0.9600 - learning_rate: 1.0000e-05\n",
      "Epoch 48/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 298ms/step - binary_accuracy: 0.9375 - f1_metrics: 0.9231 - loss: 0.1655 - precision_1: 1.0000 - recall_1: 0.8571 - val_binary_accuracy: 0.9265 - val_f1_metrics: 0.9121 - val_loss: 0.1781 - val_precision_1: 0.8571 - val_recall_1: 0.9600 - learning_rate: 1.0000e-05\n",
      "Epoch 49/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 918ms/step - binary_accuracy: 0.9443 - f1_metrics: 0.9241 - loss: 0.1669 - precision_1: 0.9352 - recall_1: 0.9099 - val_binary_accuracy: 0.9265 - val_f1_metrics: 0.9121 - val_loss: 0.1825 - val_precision_1: 0.8571 - val_recall_1: 0.9600 - learning_rate: 1.0000e-05\n",
      "Epoch 50/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 304ms/step - binary_accuracy: 0.8750 - f1_metrics: 0.8750 - loss: 0.2747 - precision_1: 1.0000 - recall_1: 0.7778 - val_binary_accuracy: 0.9265 - val_f1_metrics: 0.9121 - val_loss: 0.1825 - val_precision_1: 0.8571 - val_recall_1: 0.9600 - learning_rate: 1.0000e-05\n"
     ]
    }
   ],
   "source": [
    "bs = 16  # размер батча\n",
    "\n",
    "history = model_cats.fit(\n",
    "    datagen.flow(x_train, y_train, batch_size=bs),\n",
    "    validation_data=(x_val, y_val),\n",
    "    steps_per_epoch=len(x_train)//bs,\n",
    "    epochs=50,\n",
    "    callbacks=[tb_callback, annealing]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5fbce8c5-c0eb-4d75-a1ac-9af56d23be06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 688ms/step - binary_accuracy: 0.8841 - f1_metrics: 0.8639 - loss: 0.2372 - precision_1: 0.8846 - recall_1: 0.8214\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.23724624514579773,\n",
       " 0.8840579986572266,\n",
       " 0.8846153616905212,\n",
       " 0.8214285969734192,\n",
       " 0.8639347553253174]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cats.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa173f1b-f229-4618-b834-1ff016aae5e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
